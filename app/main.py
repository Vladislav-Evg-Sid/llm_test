from fastapi import FastAPI

from llm_plug import LlamaChatbot

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä FastAPI
app = FastAPI(title="Heavy Class Demo")


@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LlamaChatbot –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    print("üîÑ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    # –ü—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä - –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è
    heavy_instance = LlamaChatbot()
    print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ")


@app.post("/generate_text")
async def generate_endpoint(user_request: str):
    llm = LlamaChatbot()
    try:
        result = llm.generate_response(user_request)
        return {
            "status": "success",
            "data": result
        }
    except:
        return {
            "status": "failed",
            "data": "–ù–µ—Ç —Ñ–∞–π–ª–∞"
        }
