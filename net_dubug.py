import os
os.environ["HF_HUB_DISABLE_PROGRESS_BARS"] = "1"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch
import requests
import time

print("üöÄ –ó–ê–ü–£–°–ö –£–ü–†–û–©–Å–ù–ù–û–ô –í–ï–†–°–ò–ò –ë–ï–ó ACCELERATE")
print("=" * 50)

class SimpleChatbot:
    _instance = None

    def __init__(self, name="sberbank-ai/rugpt3small_based_on_gpt2"):
        if SimpleChatbot._instance is not None:
            return
            
        print("‚ö° –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...")
        start_time = time.time()
        
        try:
            # 1. –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–±—ã—Å—Ç—Ä–æ)
            print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä...")
            self.tokenizer = GPT2Tokenizer.from_pretrained(name)
            self.tokenizer.pad_token = self.tokenizer.eos_token
            print("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            # 2. –ú–æ–¥–µ–ª—å (–ë–ï–ó –ª—é–±—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π)
            print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 2-5 –º–∏–Ω—É—Ç)...")
            
            # –í–ê–†–ò–ê–ù–¢ –ê: –ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
            self.model = GPT2LMHeadModel.from_pretrained(
                name,
                torch_dtype=torch.float32
                # –ù–ò–ö–ê–ö–ò–• low_cpu_mem_usage, device_map –∏ —Ç.–¥.
            )
            
            self.model.eval()
            
            load_time = time.time() - start_time
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.1f} —Å–µ–∫—É–Ω–¥")
            print("üéâ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
            
            SimpleChatbot._instance = self
            
        except Exception as e:
            print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = SimpleChatbot()
        return cls._instance
    
    def generate_response(self, user_input):
        print(f"üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è: '{user_input}'")
        
        try:
            inputs = self.tokenizer.encode(user_input, return_tensors="pt")
            
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_new_tokens=50,  # –£–º–µ–Ω—å—à–∏–ª –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    do_sample=True,
                    temperature=0.7,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            clean_response = response.replace(user_input, "").strip()
            
            print(f"üìù –û—Ç–≤–µ—Ç: '{clean_response}'")
            return clean_response
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"

# ========== –¢–ï–°–¢–û–í–´–ô –°–¢–ï–ù–î ==========
if __name__ == "__main__":
    print("üß™ –¢–ï–°–¢–ò–†–£–ï–ú –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–¨...")
    print("‚è∞ –û–∂–∏–¥–∞–π—Ç–µ 2-5 –º–∏–Ω—É—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏")
    print("-" * 40)
    
    try:
        # –¢–µ—Å—Ç 1: –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä
        bot = SimpleChatbot.get_instance()
        
        # –¢–µ—Å—Ç 2: –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        test_text = "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"
        print(f"\nüìã –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: '{test_text}'")
        
        response = bot.generate_response(test_text)
        print(f"‚úÖ –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù! –û—Ç–≤–µ—Ç: '{response}'")
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù: {e}")
        
    print("=" * 50)