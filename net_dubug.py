import os
os.environ["HF_HUB_DISABLE_PROGRESS_BARS"] = "1"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "0"  # –û—Ç–∫–ª—é—á–∞–µ–º —É—Å–∫–æ—Ä–µ–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch
import requests
import time

print("‚ö° –ó–∞–≥—Ä—É–∑–∫–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏...")

# –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
from transformers.utils.hub import http_get

def custom_http_get(url, temp_file, proxies=None, resume_size=0, headers=None, timeout=180):
    return http_get(url, temp_file, proxies=proxies, resume_size=resume_size, headers=headers, timeout=timeout)

# –ú–æ–Ωkey-patch –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ç–∞–π–º–∞—É—Ç–∞
import transformers.modeling_utils
transformers.modeling_utils.http_get = custom_http_get

class LlamaChatbot:
    def __init__(self, name="sberbank-ai/rugpt3small_based_on_gpt2"):
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä...")
        self.tokenizer = GPT2Tokenizer.from_pretrained(name)
        self.tokenizer.pad_token = self.tokenizer.eos_token
        print("‚úÖ –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤")
        
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 2-3 –º–∏–Ω—É—Ç—ã)...")
        start_time = time.time()
        
        self.model = GPT2LMHeadModel.from_pretrained(
            name,
            torch_dtype=torch.float32,
            low_cpu_mem_usage=True,  # –í–∞–∂–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤!
            force_download=True,     # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º
            resume_download=False    # –ó–∞–ø—Ä–µ—â–∞–µ–º –¥–æ–∫–∞—á–∫—É
        )
        self.model.eval()
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {time.time()-start_time:.1f}—Å–µ–∫")